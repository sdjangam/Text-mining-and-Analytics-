{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Keyword Extraction**\n",
    "In a nutshell, keyword extraction is a methodology to automatically detect important words that can be used to represent the text and can be used for topic modeling. This is a very efficient way to get insights from a huge amount of unstructured text data.\n",
    "\n",
    "### **Libraries that help in extracting the keywords**\n",
    "1. spaCy\n",
    "2. YAKE\n",
    "3. Rake-Nltk\n",
    "4. Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. spaCY**\n",
    "spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Required Libraries '''\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"spaCy is an open-source software library for advanced natural language processing, written in the programming \n",
    "          languages Python and Cython. The library is published under the MIT license and its main developers are Matthew \n",
    "          Honnibal and Ines Montani, the founders of the software company Explosion.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-30 11:10:59.320256: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-01-30 11:10:59.320317: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.1.0) (3.1.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.19.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.50.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.11.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (20.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.24.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.3.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Attempting uninstall: en-core-web-sm\n",
      "    Found existing installation: en-core-web-sm 2.2.0\n",
      "    Uninstalling en-core-web-sm-2.2.0:\n",
      "      Successfully uninstalled en-core-web-sm-2.2.0\n",
      "Successfully installed en-core-web-sm-3.1.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' creating an instance '''\n",
    "sp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_spacy = sp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(MIT, Matthew \n",
      "          Honnibal, Ines Montani, Explosion)\n"
     ]
    }
   ],
   "source": [
    "print(doc_spacy.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. YAKE**\n",
    "`Yake` library selects the most important keywords using the text statistical features method from the article. With the help of YAKE, you can control the extracted keyword word count and other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yake\n",
      "  Downloading yake-0.4.8-py2.py3-none-any.whl (60 kB)\n",
      "Collecting segtok\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: tabulate in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from yake) (0.8.9)\n",
      "Requirement already satisfied: click>=6.0 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from yake) (7.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from yake) (1.19.2)\n",
      "Collecting jellyfish\n",
      "  Downloading jellyfish-0.9.0-cp38-cp38-win_amd64.whl (26 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from yake) (2.5)\n",
      "Requirement already satisfied: regex in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from segtok->yake) (2020.10.15)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from networkx->yake) (4.4.2)\n",
      "Installing collected packages: segtok, jellyfish, yake\n",
      "Successfully installed jellyfish-0.9.0 segtok-1.5.11 yake-0.4.8\n"
     ]
    }
   ],
   "source": [
    "!pip install yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' required libraries '''\n",
    "\n",
    "import yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"spaCy is an open-source software library for advanced natural language processing, written in the programming \n",
    "          languages Python and Cython. The library is published under the MIT license and its main developers are Matthew \n",
    "          Honnibal and Ines Montani, the founders of the software company Explosion.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **initializing some parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"en\"\n",
    "max_ngram_size = 3\n",
    "deduplication_threshold = 0.9\n",
    "numOfKeywords = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' creating an instance '''\n",
    "kw_extractor = yake.KeywordExtractor()\n",
    "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, \n",
    "                                            top=numOfKeywords, features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('programming languages Python', 0.001295347548560416)\n",
      "('natural language processing', 0.002012136772192602)\n",
      "('advanced natural language', 0.0026621455770583914)\n",
      "('Python and Cython', 0.0035840985079775055)\n",
      "('open-source software library', 0.008298152696966859)\n",
      "('languages Python', 0.009390717577572831)\n",
      "('language processing', 0.01453240965208459)\n",
      "('software company Explosion', 0.015993140254256993)\n",
      "('advanced natural', 0.01840251352140607)\n",
      "('natural language', 0.019161829017826378)\n",
      "('programming languages', 0.019161829017826378)\n",
      "('open-source software', 0.032652195076937375)\n",
      "('Ines Montani', 0.03375876229391358)\n",
      "('Matthew Honnibal', 0.04096703831447956)\n",
      "('Honnibal and Ines', 0.04096703831447956)\n",
      "('Cython', 0.053691021027863564)\n",
      "('software library', 0.05857047036380304)\n",
      "('company Explosion', 0.06120870235178475)\n",
      "('Python', 0.06651575167590484)\n",
      "('library for advanced', 0.07441175006256819)\n"
     ]
    }
   ],
   "source": [
    "keywords = custom_kw_extractor.extract_keywords(text)\n",
    "\n",
    "for kw in keywords:\n",
    "    print(kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Rake-NLTK**\n",
    "You can form a powerful keyword extraction method by combining the Rapid Automatic Keyword Extraction (RAKE) algorithm with the NLTK toolkit. It is known as rake-nltk. It is a modified version of this algorithm. You can know more about rake-nltk here.Install the rake-nltk library using pip install rake-nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rake-nltk\n",
      "  Using cached rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
      "Collecting nltk<4.0.0,>=3.6.2\n",
      "  Using cached nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: click in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (7.1.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2022.1.18)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.50.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (0.17.0)\n",
      "Installing collected packages: nltk, rake-nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.5\n",
      "    Uninstalling nltk-3.5:\n",
      "      Successfully uninstalled nltk-3.5\n",
      "Successfully installed nltk-3.6.7 rake-nltk-1.0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install rake-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' required libraries '''\n",
    "\n",
    "from rake_nltk import Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"spaCy is an open-source software library for advanced natural language processing, written in the programming \n",
    "          languages Python and Cython. The library is published under the MIT license and its main developers are Matthew \n",
    "          Honnibal and Ines Montani, the founders of the software company Explosion.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' creating an instance '''\n",
    "rake_nltk_var = Rake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['advanced natural language processing', 'software company explosion', 'programming languages python', 'source software library', 'mit license', 'matthew honnibal', 'main developers', 'ines montani', 'library', 'written', 'spacy', 'published', 'open', 'founders', 'cython']\n"
     ]
    }
   ],
   "source": [
    "rake_nltk_var.extract_keywords_from_text(text)\n",
    "keyword_extracted = rake_nltk_var.get_ranked_phrases()\n",
    "print(keyword_extracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Gensim**\n",
    "Gensim is primarily developed for topic modeling. Over time, Gensim added other NLP tasks such as summarization, finding text similarity, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==3.4.0\n",
      "  Downloading gensim-3.4.0.tar.gz (22.2 MB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from gensim==3.4.0) (1.19.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from gensim==3.4.0) (1.5.2)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from gensim==3.4.0) (1.15.0)\n",
      "Requirement already satisfied: smart_open>=1.2.1 in c:\\users\\jgaur\\anaconda3\\lib\\site-packages (from gensim==3.4.0) (5.0.0)\n",
      "Building wheels for collected packages: gensim\n",
      "  Building wheel for gensim (setup.py): started\n",
      "  Building wheel for gensim (setup.py): finished with status 'done'\n",
      "  Created wheel for gensim: filename=gensim-3.4.0-cp38-cp38-win_amd64.whl size=22590883 sha256=147fa9de2249829c772cc994aca9f7c4872343483467aa109678e3b21c025508\n",
      "  Stored in directory: c:\\users\\jgaur\\appdata\\local\\pip\\cache\\wheels\\b4\\a4\\71\\a301cdb2b7d5d31525936fcb8dcd9a5f144578d047407f7cf9\n",
      "Successfully built gensim\n",
      "Installing collected packages: gensim\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 3.8.3\n",
      "    Uninstalling gensim-3.8.3:\n",
      "      Successfully uninstalled gensim-3.8.3\n",
      "Successfully installed gensim-3.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim==3.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' required libraries '''\n",
    "\n",
    "from gensim.summarization import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"spaCy is an open-source software library for advanced natural language processing, written in the programming \n",
    "          languages Python and Cython. The library is published under the MIT license and its main developers are Matthew \n",
    "          Honnibal and Ines Montani, the founders of the software company Explosion.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
